<!doctype html><html lang=ja-jp><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.85.0"><title>Kinectを用いたRGB-Dデータセットのまとめ</title><link rel=canonical href=https://raahii.github.io/posts/kinect-rgbd-dataset/><link href=https://raahii.github.io/favicon.ico rel=icon type=image/x-icon><meta property="og:title" content="Kinectを用いたRGB-Dデータセットのまとめ"><meta property="og:description" content="はじめに 卒研でRGB-Dデータを使う研究をやっていたので、その時に調べた内容について軽くまとめます。
タイトルでは&#34;Kinectを用いた&#34;となっていますが、実際はそこに拘りはありません。ただ、研究分野でかなりよくKinectが使われているので、RGB-Dに関わる研究を探す場合には同時にKinectの文脈でも探したほうが良いと思います。Google Scholarでも&#34;kinect&#34;の方がよくヒットします。
 Google Scholar 'rgbd'    Google Scholar 'kinect'   さて、実際にデータセットについてまとめようと作業を始めたのですが、せっかくなので表にまとめようと思い、早々に挫折しました。そこで、調べる中で見つけたRGB-Dデータセットのサーベイ論文をシェアすることにします。
文献リスト まず、Kinectから取得されるRGB-Dデータ（及び音声データ）の応用をまとめている論文があります。Kinectから取ったデータの使い道のイメージをつかめると思うのでおすすめです。
 A Survey of Applications and Human Motion Recognition with Microsoft Kinect  論文  RGBD datasets: Past, present and future (2016)   データセットの種類（タスク）毎に表で整理してありわかりやすいです。データセットの説明や作成年だけでなく、サムネイルが付いていて、形式（Video?/Skelton?）についても言及があります。  表の例（本項の論文より引用）     RGB-D datasets using microsoft kinect or similar sensors: a survey. (2017)   これも種類に応じて章分けしてまとめてくれています。一応表もありますが見づらいです。個々のデータセットに対し、サンプル数やラベル情報を簡潔に文章でまとめてくれています。最初のツリー画像が良い感じです。  データセット木（本項の論文より引用）     RGB-D-based Action Recognition Datasets: A Survey (2016)   アクション認識に絞ってまとめられているのですが、文章でも表でもかなりよくまとめられています。とうか逆にタスクを絞ったからこそまとめやすいのかもしれませんね。ラベル数とサンプル数で図に落とし込まれているのもわかりやすかったです。  データセットの比較の図（本項の論文より引用）     A Survey of Datasets for Human Gesture Recognition (2014)   これはジェスチャ認識に絞ってまとめられたものです。これも表あるのでわかりやすいです。あと、Availability (Public, Public on Request or Not Yet)の項もあるのが特徴です。"><meta property="og:type" content="article"><meta property="og:url" content="https://raahii.github.io/posts/kinect-rgbd-dataset/"><meta property="article:section" content="post"><meta property="article:published_time" content="2018-03-01T18:23:10+09:00"><meta property="article:modified_time" content="2018-03-01T18:23:10+09:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kinectを用いたRGB-Dデータセットのまとめ"><meta name=twitter:description content="はじめに 卒研でRGB-Dデータを使う研究をやっていたので、その時に調べた内容について軽くまとめます。
タイトルでは&#34;Kinectを用いた&#34;となっていますが、実際はそこに拘りはありません。ただ、研究分野でかなりよくKinectが使われているので、RGB-Dに関わる研究を探す場合には同時にKinectの文脈でも探したほうが良いと思います。Google Scholarでも&#34;kinect&#34;の方がよくヒットします。
 Google Scholar 'rgbd'    Google Scholar 'kinect'   さて、実際にデータセットについてまとめようと作業を始めたのですが、せっかくなので表にまとめようと思い、早々に挫折しました。そこで、調べる中で見つけたRGB-Dデータセットのサーベイ論文をシェアすることにします。
文献リスト まず、Kinectから取得されるRGB-Dデータ（及び音声データ）の応用をまとめている論文があります。Kinectから取ったデータの使い道のイメージをつかめると思うのでおすすめです。
 A Survey of Applications and Human Motion Recognition with Microsoft Kinect  論文  RGBD datasets: Past, present and future (2016)   データセットの種類（タスク）毎に表で整理してありわかりやすいです。データセットの説明や作成年だけでなく、サムネイルが付いていて、形式（Video?/Skelton?）についても言及があります。  表の例（本項の論文より引用）     RGB-D datasets using microsoft kinect or similar sensors: a survey. (2017)   これも種類に応じて章分けしてまとめてくれています。一応表もありますが見づらいです。個々のデータセットに対し、サンプル数やラベル情報を簡潔に文章でまとめてくれています。最初のツリー画像が良い感じです。  データセット木（本項の論文より引用）     RGB-D-based Action Recognition Datasets: A Survey (2016)   アクション認識に絞ってまとめられているのですが、文章でも表でもかなりよくまとめられています。とうか逆にタスクを絞ったからこそまとめやすいのかもしれませんね。ラベル数とサンプル数で図に落とし込まれているのもわかりやすかったです。  データセットの比較の図（本項の論文より引用）     A Survey of Datasets for Human Gesture Recognition (2014)   これはジェスチャ認識に絞ってまとめられたものです。これも表あるのでわかりやすいです。あと、Availability (Public, Public on Request or Not Yet)の項もあるのが特徴です。"><link rel=icon href=https://raahii.github.io/images/favicon.ico type=image/x-icon><link rel=stylesheet href=https://raahii.github.io/css/main.css media=all><link rel=stylesheet href="//fonts.googleapis.com/css?family=Merriweather:400|Lato:400,400italic,700"></head><body><div class=wrapper><header class=header><nav class=nav><a href=https://raahii.github.io/ class=nav-logo><img src=https://raahii.github.io/images/bird.svg width=45 height=45 alt=Logo><p class=nav-title>1ミリもわからん</p></a><ul class=nav-links><li><a href=/tags/>Tags</a></li><li><a href=/about/>About</a></li><li><a href=https://github.com/raahii target=_blank>GitHub</a></li><li><a href=https://twitter.com/raahiiy target=_blank>Twitter</a></li></ul></nav></header><main class=content role=main><article class=article><h1 class=article-title>Kinectを用いたRGB-Dデータセットのまとめ</h1><span class=article-date>March 1, 2018</span>
<span class=article-duration>1 min read</span><ul class="cp_tag01 article-categories">Categories:<li><a href=/categories/%E7%A0%94%E7%A9%B6/>研究</a></li></ul><ul class="cp_tag01 article-tags">Tags:<li><a href=/tags/%E8%AB%96%E6%96%87/>論文</a></li><li><a href=/tags/kinect/>kinect</a></li><li><a href=/tags/depth/>depth</a></li></ul><div class=article-content><h1 id=はじめに>はじめに</h1><p>卒研でRGB-Dデータを使う研究をやっていたので、その時に調べた内容について軽くまとめます。</p><p>タイトルでは"Kinectを用いた"となっていますが、実際はそこに拘りはありません。ただ、研究分野でかなりよくKinectが使われているので、RGB-Dに関わる研究を探す場合には同時にKinectの文脈でも探したほうが良いと思います。Google Scholarでも"kinect"の方がよくヒットします。</p><p><figure><img src=/images/2018/kinect-rgbd-dataset/google-scholar-rgbd.png><figcaption><h4>Google Scholar 'rgbd'</h4></figcaption></figure><figure><img src=/images/2018/kinect-rgbd-dataset/google-scholar-kinect.png><figcaption><h4>Google Scholar 'kinect'</h4></figcaption></figure></p><p>さて、実際にデータセットについてまとめようと作業を始めたのですが、<a href="https://docs.google.com/spreadsheets/d/1ETewgOneQyzSI9jKP02uhfCC8F8aS90nyjlgITzSh-o/edit?usp=sharing">せっかくなので表にまとめようと思い</a>、早々に挫折しました。そこで、<strong>調べる中で見つけたRGB-Dデータセットのサーベイ論文をシェアすることにします</strong>。</p><h1 id=文献リスト>文献リスト</h1><p>まず、Kinectから取得されるRGB-Dデータ（及び音声データ）の応用をまとめている論文があります。Kinectから取ったデータの使い道のイメージをつかめると思うのでおすすめです。</p><ul><li><a href="https://scholar.google.co.jp/scholar?hl=ja&as_sdt=0%2C5&q=A+Survey+of+Applications+and+Human+Motion+Recognition+with+Microsoft+Kinect&btnG=">A Survey of Applications and Human Motion Recognition with Microsoft Kinect</a></li></ul><h2 id=論文>論文</h2><ul><li><a href="https://scholar.google.co.jp/scholar?hl=ja&as_sdt=0%2C5&q=RGBD+Datasets%3A+Past%2C+Present+and+Future+Michael&btnG=">RGBD datasets: Past, present and future (2016)</a></li></ul><blockquote><p>データセットの種類（タスク）毎に表で整理してありわかりやすいです。データセットの説明や作成年だけでなく、サムネイルが付いていて、形式（Video?/Skelton?）についても言及があります。<figure><img src=/images/2018/kinect-rgbd-dataset/dataset-table1.png><figcaption><h4>表の例（本項の論文より引用）</h4></figcaption></figure></p></blockquote><ul><li><a href="https://scholar.google.co.jp/scholar?hl=ja&as_sdt=0%2C5&q=RGB-D+datasets+using+microsoft+kinect+or+similar+sensors%3A+a+survey.&btnG=">RGB-D datasets using microsoft kinect or similar sensors: a survey. (2017)</a></li></ul><blockquote><p>これも種類に応じて章分けしてまとめてくれています。一応表もありますが見づらいです。個々のデータセットに対し、サンプル数やラベル情報を簡潔に文章でまとめてくれています。最初のツリー画像が良い感じです。<figure><img src=/images/2018/kinect-rgbd-dataset/dataset-tree.png><figcaption><h4>データセット木（本項の論文より引用）</h4></figcaption></figure></p></blockquote><ul><li><a href="https://scholar.google.co.jp/scholar?hl=ja&as_sdt=0%2C5&q=RGB-D-based+Action+Recognition+Datasets%3A+A+Survey&btnG=">RGB-D-based Action Recognition Datasets: A Survey (2016)</a></li></ul><blockquote><p>アクション認識に絞ってまとめられているのですが、文章でも表でもかなりよくまとめられています。とうか逆にタスクを絞ったからこそまとめやすいのかもしれませんね。ラベル数とサンプル数で図に落とし込まれているのもわかりやすかったです。<figure><img src=/images/2018/kinect-rgbd-dataset/dataset-figure1.png><figcaption><h4>データセットの比較の図（本項の論文より引用）</h4></figcaption></figure></p></blockquote><ul><li><a href="https://scholar.google.co.jp/scholar?hl=ja&as_sdt=0%2C5&q=A+Survey+of+Datasets+for+Human+Gesture+Recognition&btnG=">A Survey of Datasets for Human Gesture Recognition (2014)</a></li></ul><blockquote><p>これはジェスチャ認識に絞ってまとめられたものです。これも表あるのでわかりやすいです。あと、<code>Availability (Public, Public on Request or Not Yet)</code>の項もあるのが特徴です。</p></blockquote><h2 id=web>Web</h2><p>ついでにWeb媒体の資料も載せておきます。</p><ul><li><a href=http://robonchu.hatenablog.com/entry/2017/06/11/162558>RGBDデータセットのお勉強</a></li><li><a href=http://www.michaelfirman.co.uk/RGBDdatasets/>List of RGBD datasets - Michael Firman</a></li><li><a href=http://www.cnblogs.com/alexanderkun/p/4593124.html>List of RGBD datasets - alexanderkun - 博客园</a></li></ul><h1 id=さいごに>さいごに</h1><p>今回探してみて、愚直にGoogleなどで探すと意外に辛いことがわかりました。特にKinectが発売直後の2011〜2013年のデータセットは数も多くよくヒットするのですが、新しめのデータセットはこのようなサーベイ論文を当たるほうが圧倒的に効率が良いです。あと、Skeltonがあるやつを探したいみたいな場合も、データセットのHPを見てもデータ形式が明示されてないことが多く、そもそもHPがないケースもあるので、論文当たったほうが良いですね。</p></div></article><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//raahii.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a><h3>こちらの記事もどうぞ</h3><ul class="related-content article-content"><li><a href=/posts/dvdgan-adversarial-video-generation-on-complex-datasets/>DVDGAN - "Adversarial Video Generation on Complex Datasets"</a></li><li><a href=/posts/texshop-yen-mark-problem/>TeXShopでバックスラッシュが円マークになる問題</a></li></ul></main><footer class=footer><ul class=footer-links><li><a href=https://gohugo.io/ class=footer-links-kudos>Made with <img src=https://raahii.github.io/images/hugo-logo.png width=22 height=22 alt="hugo log"></a></li></ul></footer></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-D4N0KPT2K2"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-D4N0KPT2K2',{anonymize_ip:!1})}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css integrity=sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js integrity=sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></body></html>